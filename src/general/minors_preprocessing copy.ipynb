{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1505 entries, 0 to 1504\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   1505 non-null   int64 \n",
      " 1   id           1505 non-null   int64 \n",
      " 2   zip          1505 non-null   object\n",
      " 3   file name    1505 non-null   object\n",
      " 4   entry        1505 non-null   int64 \n",
      " 5   Description  1505 non-null   object\n",
      " 6   CPV          1505 non-null   object\n",
      " 7   URI          1505 non-null   object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 94.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/minors_downloaded.csv')\n",
    "df.info()\n",
    "descriptions = df['Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0 456.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each description\n",
    "description_lengths = descriptions.apply(len)\n",
    "\n",
    "Q1 = description_lengths.quantile(0.25)\n",
    "Q3 = description_lengths.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determine outlier thresholds\n",
    "lower_threshold = Q1 - 1.5 * IQR\n",
    "upper_threshold = Q3 + 1.5 * IQR\n",
    "\n",
    "print(lower_threshold,upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1392 entries, 0 to 1391\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   1392 non-null   int64 \n",
      " 1   id           1392 non-null   int64 \n",
      " 2   zip          1392 non-null   object\n",
      " 3   file name    1392 non-null   object\n",
      " 4   entry        1392 non-null   int64 \n",
      " 5   Description  1392 non-null   object\n",
      " 6   CPV          1392 non-null   object\n",
      " 7   URI          1392 non-null   object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 87.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Filter descriptions within thresholds\n",
    "filtered_df = df[(description_lengths >= lower_threshold) & (description_lengths <= upper_threshold)]\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "print(filtered_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pablo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Pablo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pablo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's Spanish language model\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "# Download NLTK stop words\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define Spanish stop words\n",
    "spanish_stopwords = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text, language='spanish')\n",
    "    \n",
    "    # Remove unnecessary data\n",
    "    tokens = [re.sub(r'\\b\\d{2,}\\b|(?:\\d{1,2}[\\/\\-\\.]){2,}\\d{2,4}|\\b(?:tel|email)\\b', '', token) for token in tokens]\n",
    "    tokens = [token for token in tokens if token.lower() not in ['lunes', 'martes', 'miércoles', 'jueves', 'viernes', 'sábado', 'domingo', 'enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre']]\n",
    "    \n",
    "    # Remove non-alphabetic data\n",
    "    tokens = [re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑüÜ]', '', token) for token in tokens]\n",
    "    \n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in spanish_stopwords]\n",
    "    \n",
    "    # Lemmatization\n",
    "    doc = nlp(' '.join(tokens))\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_descriptions = filtered_df['Description']\n",
    "\n",
    "preprocessed_descriptions = [preprocess_text(desc) for desc in filtered_descriptions]\n",
    "filtered_df['processed_description'] = preprocessed_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new column for non preprocessed models (just lowercasing because some models are case sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['lowercase_description'] = filtered_descriptions.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1392 entries, 0 to 1391\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   zip                    1392 non-null   object\n",
      " 1   file name              1392 non-null   object\n",
      " 2   entry                  1392 non-null   int64 \n",
      " 3   Description            1392 non-null   object\n",
      " 4   CPV                    1392 non-null   object\n",
      " 5   URI                    1392 non-null   object\n",
      " 6   processed_description  1392 non-null   object\n",
      " 7   lowercase_description  1392 non-null   object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "filtered_df = filtered_df.drop(columns=['Unnamed: 0', 'id'])\n",
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "filtered_df.to_csv('../../data/minors_with_preprocessed_descriptions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
